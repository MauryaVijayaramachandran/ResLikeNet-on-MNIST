{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Maurya Vijayaramachandran \n",
        "\n",
        "Project: implementing the resnet architecture. "
      ],
      "metadata": {
        "id": "y-tHxM5NXsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries"
      ],
      "metadata": {
        "id": "MOmkuaGcX8pr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV5ZSq_FAw81"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ],
      "metadata": {
        "id": "G786SZotX-vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "rJ7YCM3bBL5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473c62a9-86a3-4d69-9edc-8ca962ccd69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset and split it into test and train sets\n",
        "\n",
        "The test and train sets are further split into\n",
        "\n",
        "a. Features X_train , X_test \n",
        "\n",
        "b. Labels y_train, y_test"
      ],
      "metadata": {
        "id": "uADmqZ4DYBqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1,28,28,1).astype(\"float32\")/255.0\n",
        "x_test = x_test.reshape(-1,28,28,1).astype(\"float32\")/255.0"
      ],
      "metadata": {
        "id": "QpZ_9NWOBaLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing the data"
      ],
      "metadata": {
        "id": "epn6m3ciYPEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1r7YsUkRedS",
        "outputId": "f0498bf2-5271-4e76-a272-61aa349dbab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a dense layer "
      ],
      "metadata": {
        "id": "HwEihk5TJVgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense(layers.Layer):\n",
        "  \"\"\"\n",
        "    A dense layer applies a linear transformation to the input data and produces an output of a specified size.\n",
        "\n",
        "    Attributes:\n",
        "        units: An integer representing the number of units in the layer.\n",
        "\n",
        "    Methods:\n",
        "        __init__(self, units): Initializes the Dense object with the specified number of units.\n",
        "        build(self, input_shape): Creates and initializes the trainable parameters of the layer.\n",
        "        call(self, inputs): Defines the forward pass of the layer.\n",
        "\n",
        "    Example usage:\n",
        "        dense_layer = Dense(units=64)\n",
        "  \"\"\"\n",
        "  def __init__(self,units):\n",
        "        \"\"\"\n",
        "        Initializes the Dense object with the specified number of units.\n",
        "\n",
        "        Args:\n",
        "            units: An integer representing the number of units in the layer.\n",
        "        \"\"\"\n",
        "    super().__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "         \"\"\"\n",
        "        Creates and initializes the trainable parameters of the layer.\n",
        "\n",
        "        Args:\n",
        "            input_shape: A tuple representing the shape of the input to the layer.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.w = self.add_weight(\n",
        "        name = \"w\",\n",
        "        shape = (input_shape[-1], self.units),\n",
        "        initializer = \"random_normal\",\n",
        "        trainable = True,\n",
        "\n",
        "    )\n",
        "        self.b = self.add_weight(\n",
        "        name = \"b\",\n",
        "        shape = (self.units,),\n",
        "        initializer= \"zeros\",\n",
        "        trainable = True,\n",
        "    )\n",
        "  def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the layer.\n",
        "\n",
        "        Args:\n",
        "            inputs: The input tensor to the layer.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the output of the layer.\n",
        "        \"\"\"\n",
        "    return tf.matmul(inputs, self.w)+ self.b"
      ],
      "metadata": {
        "id": "Jf5n4VK-JUmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the CNN block"
      ],
      "metadata": {
        "id": "JVEi-4o-ZrJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(layers.Layer):\n",
        " \"\"\"\n",
        "    A convolutional block consisting of a convolutional layer, batch normalization, and a ReLU activation function.\n",
        "\n",
        "    Attributes:\n",
        "        out_channels: An integer representing the number of output channels in the convolutional layer.\n",
        "        kernel_size: An integer or tuple/list of 2 integers representing the height and width of the convolutional kernel.\n",
        "\n",
        "    Methods:\n",
        "        __init__(self, out_channels, kernel_size=3): Initializes the CNNBlock object with the specified number of output channels and kernel size.\n",
        "        call(self, input_tensor, training=False): Defines the forward pass of the layer.\n",
        "\n",
        "    Example usage:\n",
        "        cnn_block = CNNBlock(out_channels=64, kernel_size=(3, 3))\n",
        "\"\"\"\n",
        "  def __init__(self, out_channels, kernel_size = 3):\n",
        "        \"\"\"\n",
        "        Initializes the CNNBlock object with the specified number of output channels and kernel size.\n",
        "\n",
        "        Args:\n",
        "            out_channels: An integer representing the number of output channels in the convolutional layer.\n",
        "            kernel_size: An integer or tuple/list of 2 integers representing the height and width of the convolutional kernel.\n",
        "                Default is 3.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "    super().__init__()\n",
        "    self.conv = layers.Conv2D(out_channels, kernel_size,padding = \"same\")\n",
        "    self.bn = layers.BatchNormalization()\n",
        "    self.relu = MyReLU()\n",
        "  def call(self,input_tensor, training = False):\n",
        "    \"\"\"\n",
        "        Defines the forward pass of the layer.\n",
        "\n",
        "        Args:\n",
        "            input_tensor: The input tensor to the layer.\n",
        "            training: A boolean indicating whether the layer is in training mode. Default is False.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the output of the layer.\n",
        "    \"\"\"\n",
        "    x = self.conv(input_tensor)\n",
        "    x = self.bn(x, training = training)\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "VZ6mAwr3BwAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the Rectified Linear Unit Activation function"
      ],
      "metadata": {
        "id": "B_9BWo5FZtyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyReLU(layers.Layer):\n",
        "    \"\"\"\n",
        "    A custom ReLU activation function.\n",
        "\n",
        "    Methods:\n",
        "        __init__(self): Initializes the MyReLU object.\n",
        "        call(self, x): Defines the forward pass of the layer.\n",
        "\n",
        "    Example usage:\n",
        "        my_relu = MyReLU()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the MyReLU object.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the layer.\n",
        "\n",
        "        Args:\n",
        "            x: The input tensor to the layer.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the output of the layer.\n",
        "        \"\"\"\n",
        "        return tf.math.maximum(x, 0)\n"
      ],
      "metadata": {
        "id": "2G6ruuL5Liey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.Sequential(\n",
        "#     [\n",
        "#      CNNBlock(32),\n",
        "#      CNNBlock(64),\n",
        "#      CNNBlock(128),\n",
        "#      layers.Flatten(),\n",
        "#      layers.Dense(10)\n",
        "#     ]\n",
        "# )"
      ],
      "metadata": {
        "id": "Fo7seWmoCoYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write definition here "
      ],
      "metadata": {
        "id": "CtsvrmfbZu3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(layers.Layer):\n",
        "    \"\"\"Docstring here\n",
        "  \"\"\"\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.cnn1 = CNNBlock(channels[0])\n",
        "    self.cnn2 = CNNBlock(channels[1])\n",
        "    self.cnn3 = CNNBlock(channels[2])\n",
        "    self.pooling = layers.MaxPooling2D()\n",
        "    self.identity_mapping = layers.Conv2D(channels[1],kernel_size =1, padding = \"same\" )\n",
        "  def call(self, input_tensor, training = False):\n",
        "    x = self.cnn1(input_tensor, training = training)\n",
        "    x = self.cnn2(x, training = training)\n",
        "    x = self.cnn3(\n",
        "        x+self.identity_mapping(input_tensor), training = training\n",
        "    )\n",
        "    return self.pooling(x)"
      ],
      "metadata": {
        "id": "uOg0qGtpEF__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the residual blocks"
      ],
      "metadata": {
        "id": "NAq9OisgZvvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(layers.Layer):\n",
        "    \"\"\"\n",
        "    A residual block consisting of three convolutional blocks, a max pooling layer, and an identity mapping.\n",
        "\n",
        "    Attributes:\n",
        "        channels: A tuple of 3 integers representing the number of output channels for each of the convolutional blocks.\n",
        "\n",
        "    Methods:\n",
        "        __init__(self, channels): Initializes the ResBlock object with the specified number of output channels for each block.\n",
        "        call(self, input_tensor, training=False): Defines the forward pass of the layer.\n",
        "\n",
        "    Example usage:\n",
        "        res_block = ResBlock(channels=(64, 64, 256))\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels):\n",
        "        \"\"\"\n",
        "        Initializes the ResBlock object with the specified number of output channels for each block.\n",
        "\n",
        "        Args:\n",
        "            channels: A tuple of 3 integers representing the number of output channels for each of the convolutional blocks.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.cnn1 = CNNBlock(channels[0])\n",
        "        self.cnn2 = CNNBlock(channels[1])\n",
        "        self.cnn3 = CNNBlock(channels[2])\n",
        "        self.pooling = layers.MaxPooling2D()\n",
        "        self.identity_mapping = layers.Conv2D(channels[1], kernel_size=1, padding=\"same\")\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the layer.\n",
        "\n",
        "        Args:\n",
        "            input_tensor: The input tensor to the layer.\n",
        "            training: A boolean indicating whether the layer is in training mode. Default is False.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the output of the layer.\n",
        "        \"\"\"\n",
        "        x = self.cnn1(input_tensor, training=training)\n",
        "        x = self.cnn2(x, training=training)\n",
        "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training)\n",
        "        return self.pooling(x)\n"
      ],
      "metadata": {
        "id": "7CKG2fFDFhUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model and passing in the number of classes. \n",
        "\n",
        "1. It is 10 for MNIST"
      ],
      "metadata": {
        "id": "lznI6GPOZ9g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = reslike(num_classes = 10)"
      ],
      "metadata": {
        "id": "vzVW7bFlHCZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The compilation block"
      ],
      "metadata": {
        "id": "EcnZxORRZxPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "    metrics= [\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "8BcE8ENAGzvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training block"
      ],
      "metadata": {
        "id": "AzU14mEhZyZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(x_train,y_train, batch_size = 64, epochs=3, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80aP-C4eDKg-",
        "outputId": "7be3d6b6-cfa7-4c24-ab0d-4c185a1f46ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['reslike/res_block_1/cnn_block_3/conv2d_4/kernel:0', 'reslike/res_block_1/cnn_block_3/conv2d_4/bias:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/gamma:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/beta:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/kernel:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/bias:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/gamma:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/beta:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/kernel:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/bias:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/gamma:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/beta:0', 'reslike/res_block_1/conv2d_7/kernel:0', 'reslike/res_block_1/conv2d_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['reslike/res_block_1/cnn_block_3/conv2d_4/kernel:0', 'reslike/res_block_1/cnn_block_3/conv2d_4/bias:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/gamma:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/beta:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/kernel:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/bias:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/gamma:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/beta:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/kernel:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/bias:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/gamma:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/beta:0', 'reslike/res_block_1/conv2d_7/kernel:0', 'reslike/res_block_1/conv2d_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['reslike/res_block_1/cnn_block_3/conv2d_4/kernel:0', 'reslike/res_block_1/cnn_block_3/conv2d_4/bias:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/gamma:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/beta:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/kernel:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/bias:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/gamma:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/beta:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/kernel:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/bias:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/gamma:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/beta:0', 'reslike/res_block_1/conv2d_7/kernel:0', 'reslike/res_block_1/conv2d_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['reslike/res_block_1/cnn_block_3/conv2d_4/kernel:0', 'reslike/res_block_1/cnn_block_3/conv2d_4/bias:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/gamma:0', 'reslike/res_block_1/cnn_block_3/batch_normalization_3/beta:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/kernel:0', 'reslike/res_block_1/cnn_block_4/conv2d_5/bias:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/gamma:0', 'reslike/res_block_1/cnn_block_4/batch_normalization_4/beta:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/kernel:0', 'reslike/res_block_1/cnn_block_5/conv2d_6/bias:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/gamma:0', 'reslike/res_block_1/cnn_block_5/batch_normalization_5/beta:0', 'reslike/res_block_1/conv2d_7/kernel:0', 'reslike/res_block_1/conv2d_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 - 43s - loss: 0.1060 - accuracy: 0.9706 - 43s/epoch - 46ms/step\n",
            "Epoch 2/3\n",
            "938/938 - 30s - loss: 0.0376 - accuracy: 0.9885 - 30s/epoch - 32ms/step\n",
            "Epoch 3/3\n",
            "938/938 - 28s - loss: 0.0311 - accuracy: 0.9902 - 28s/epoch - 30ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bb04f3c10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation block "
      ],
      "metadata": {
        "id": "9Ci7i7oxZzeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.evaluate(x_test, y_test, batch_size = 64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQo1ZXV2DcJI",
        "outputId": "8c6087a2-72dc-4b61-f79f-ffe9f64606a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 - 2s - loss: 0.1043 - accuracy: 0.9725 - 2s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10434883087873459, 0.9725000262260437]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "eVn2U-M2aaOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/model/\")"
      ],
      "metadata": {
        "id": "RGYu2BTTSDLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.model_summary().summary()"
      ],
      "metadata": {
        "id": "O_J8MmcGG38R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12fe6f7-c386-4d29-aa07-99226fa33b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " res_block (ResBlock)        (None, 14, 14, 64)        28640     \n",
            "                                                                 \n",
            " res_block_2 (ResBlock)      (None, 7, 7, 512)         1569408   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,603,178\n",
            "Trainable params: 1,601,130\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}